{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from enum import Enum\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "import datetime\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "dataset_name = \"oxford_flowers102\"\n",
    "dataset_repetitions = 5\n",
    "num_epochs = 50 # train for at least 50 epochs for good results\n",
    "image_size = 256\n",
    "# KID = Kernel Inception Distance, see related section\n",
    "kid_image_size =286\n",
    "kid_diffusion_steps = 5\n",
    "plot_diffusion_steps = 20\n",
    "\n",
    "# sampling\n",
    "min_signal_rate = 0.02\n",
    "max_signal_rate = 0.95\n",
    "\n",
    "# architecture\n",
    "embedding_dims = 32\n",
    "embedding_max_frequency = 1000.0\n",
    "widths = [64, 96, 128, 160]\n",
    "block_depth = 4\n",
    "\n",
    "# optimization\n",
    "batch_size = 32\n",
    "ema = 0.999\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-4\n",
    "\n",
    "#dataset_name: 사용할 데이터셋의 이름\n",
    "#dataset_repetitions: 데이터셋을 몇 번 반복해서 사용할지 결정\n",
    "#num_epochs: 모델 학습을 몇 번 에폭(epoch) 돌릴지 결정\n",
    "#image_size: 생성할 이미지의 크기\n",
    "#kid_image_size: KID(Kernel Inception Distance) 계산에 사용될 이미지 크기\n",
    "#kid_diffusion_steps: KID 계산에 사용될 Diffusion step 수\n",
    "#plot_diffusion_steps: 시각화에 사용될 Diffusion step 수\n",
    "#min_signal_rate, max_signal_rate: 신호 비율(signal rate) 범위, 생성기가 이미지에서 랜덤하게 선택할 픽셀의 비율\n",
    "#embedding_dims: 임베딩 차원\n",
    "#embedding_max_frequency: 임베딩 최대 주파수\n",
    "#widths: 생성자와 판별자에서 사용될 네트워크 레이어의 폭(width) 리스트\n",
    "#block_depth: 생성자와 판별자에서 사용될 Residual block 개수\n",
    "#batch_size: 한 번에 처리할 이미지의 개수\n",
    "#ema: Exponential Moving Average(EMA) decay 값\n",
    "#learning_rate: 학습률\n",
    "#weight_decay: 가중치 감쇠 값"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 훈련용 마스크 답지  및 병변여부 \n",
    "train_x_filenames = glob.glob('../data/d2/*.png')\n",
    "\n",
    "train_x = np.zeros((len(train_x_filenames),image_size,image_size,3),dtype=np.int32)\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "buffer_size = image_size\n",
    "\n",
    "def normalize_img(img):\n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    # Map values in the range [-1, 1]\n",
    "    return img/255  ############\n",
    "\n",
    "\n",
    "for (index, image) in enumerate(train_x_filenames[:]):\n",
    "    \n",
    "    img1=PIL.Image.open(image).convert(\"RGB\")\n",
    "    if(img1.size[0]>=img1.size[1]):\n",
    "        ratio=image_size/img1.size[0]\n",
    "    else:\n",
    "        ratio=image_size/img1.size[1]\n",
    "    width=ratio*img1.size[0]\n",
    "    height=ratio*img1.size[1]\n",
    "    height_padding_size=int((image_size-height)/2)\n",
    "    width_padding_size=int((image_size-width)/2)\n",
    "    img1=np.array(img1.resize((int(width),int(height))))\n",
    "    train_x[index,height_padding_size:-height_padding_size,:] = img1\n",
    "# 훈련용 마스크 답지  및 병변여부 \n",
    "tf_train_x=tf.data.Dataset.from_tensor_slices(train_x)\n",
    "\n",
    "tf_train_x=(tf_train_x.map(normalize_img, num_parallel_calls=autotune).cache()\n",
    "    .batch(batch_size)).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KID(Kernel Inception Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KID(keras.metrics.Metric):\n",
    "    def __init__(self, name, **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "\n",
    "        # KID is estimated per batch and is averaged across batches\n",
    "        self.kid_tracker = keras.metrics.Mean(name=\"kid_tracker\")\n",
    "\n",
    "        # a pretrained InceptionV3 is used without its classification layer\n",
    "        # transform the pixel values to the 0-255 range, then use the same\n",
    "        # preprocessing as during pretraining\n",
    "        self.encoder = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=(image_size, image_size, 3)),\n",
    "                layers.Rescaling(255.0),\n",
    "                layers.Resizing(height=kid_image_size, width=kid_image_size),\n",
    "                layers.Lambda(keras.applications.inception_v3.preprocess_input),\n",
    "                keras.applications.InceptionV3(\n",
    "                    include_top=False,\n",
    "                    input_shape=(kid_image_size, kid_image_size, 3),\n",
    "                    weights=\"imagenet\",\n",
    "                ),\n",
    "                layers.GlobalAveragePooling2D(),\n",
    "            ],\n",
    "            name=\"inception_encoder\",\n",
    "        )\n",
    "\n",
    "    def polynomial_kernel(self, features_1, features_2):\n",
    "        feature_dimensions = tf.cast(tf.shape(features_1)[1], dtype=tf.float32)\n",
    "        return (features_1 @ tf.transpose(features_2) / feature_dimensions + 1.0) ** 3.0\n",
    "\n",
    "    def update_state(self, real_images, generated_images, sample_weight=None):\n",
    "        real_features = self.encoder(real_images, training=False)\n",
    "        generated_features = self.encoder(generated_images, training=False)\n",
    "\n",
    "        # compute polynomial kernels using the two sets of features\n",
    "        kernel_real = self.polynomial_kernel(real_features, real_features)\n",
    "        kernel_generated = self.polynomial_kernel(\n",
    "            generated_features, generated_features\n",
    "        )\n",
    "        kernel_cross = self.polynomial_kernel(real_features, generated_features)\n",
    "\n",
    "        # estimate the squared maximum mean discrepancy using the average kernel values\n",
    "        batch_size = tf.shape(real_features)[0]\n",
    "        batch_size_f = tf.cast(batch_size, dtype=tf.float32)\n",
    "        mean_kernel_real = tf.reduce_sum(kernel_real * (1.0 - tf.eye(batch_size))) / (\n",
    "            batch_size_f * (batch_size_f - 1.0)\n",
    "        )\n",
    "        mean_kernel_generated = tf.reduce_sum(\n",
    "            kernel_generated * (1.0 - tf.eye(batch_size))\n",
    "        ) / (batch_size_f * (batch_size_f - 1.0))\n",
    "        mean_kernel_cross = tf.reduce_mean(kernel_cross)\n",
    "        kid = mean_kernel_real + mean_kernel_generated - 2.0 * mean_kernel_cross\n",
    "\n",
    "        # update the average KID estimate\n",
    "        self.kid_tracker.update_state(kid)\n",
    "\n",
    "    def result(self):\n",
    "        return self.kid_tracker.result()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.kid_tracker.reset_state()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(x):\n",
    "    embedding_min_frequency = 1.0\n",
    "    frequencies = tf.exp(\n",
    "        tf.linspace(\n",
    "            tf.math.log(embedding_min_frequency),\n",
    "            tf.math.log(embedding_max_frequency),\n",
    "            embedding_dims // 2,\n",
    "        )\n",
    "    )\n",
    "    angular_speeds = 2.0 * math.pi * frequencies\n",
    "    embeddings = tf.concat(\n",
    "        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def ResidualBlock(width):\n",
    "    def apply(x):\n",
    "        input_width = x.shape[3]\n",
    "        if input_width == width:\n",
    "            residual = x\n",
    "        else:\n",
    "            residual = layers.Conv2D(width, kernel_size=1)(x)\n",
    "        x = layers.BatchNormalization(center=False, scale=False)(x)\n",
    "        x = layers.Conv2D(\n",
    "            width, kernel_size=3, padding=\"same\", activation=keras.activations.swish\n",
    "        )(x)\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
    "        x = layers.Add()([x, residual])\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def DownBlock(width, block_depth):\n",
    "    def apply(x):\n",
    "        x, skips = x\n",
    "        for _ in range(block_depth):\n",
    "            x = ResidualBlock(width)(x)\n",
    "            skips.append(x)\n",
    "        x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def UpBlock(width, block_depth):\n",
    "    def apply(x):\n",
    "        x, skips = x\n",
    "        x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
    "        for _ in range(block_depth):\n",
    "            x = layers.Concatenate()([x, skips.pop()])\n",
    "            x = ResidualBlock(width)(x)\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def get_network(image_size, widths, block_depth):\n",
    "    noisy_images = keras.Input(shape=(image_size, image_size, 3))\n",
    "    noise_variances = keras.Input(shape=(1, 1, 1))\n",
    "\n",
    "    e = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
    "    e = layers.UpSampling2D(size=image_size, interpolation=\"nearest\")(e)\n",
    "\n",
    "    x = layers.Conv2D(widths[0], kernel_size=1)(noisy_images)\n",
    "    x = layers.Concatenate()([x, e])\n",
    "\n",
    "    skips = []\n",
    "    for width in widths[:-1]:\n",
    "        x = DownBlock(width, block_depth)([x, skips])\n",
    "\n",
    "    for _ in range(block_depth):\n",
    "        x = ResidualBlock(widths[-1])(x)\n",
    "\n",
    "    for width in reversed(widths[:-1]):\n",
    "        x = UpBlock(width, block_depth)([x, skips])\n",
    "\n",
    "    x = layers.Conv2D(3, kernel_size=1, kernel_initializer=\"zeros\")(x)\n",
    "\n",
    "    return keras.Model([noisy_images, noise_variances], x, name=\"residual_unet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GanModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(keras.Model):\n",
    "    def __init__(self, image_size, widths, block_depth):\n",
    "        super().__init__()\n",
    "\n",
    "        self.normalizer = layers.Normalization()\n",
    "        self.network = get_network(image_size, widths, block_depth)\n",
    "        self.ema_network = keras.models.clone_model(self.network)\n",
    "\n",
    "    def compile(self, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.noise_loss_tracker = keras.metrics.Mean(name=\"n_loss\")\n",
    "        self.image_loss_tracker = keras.metrics.Mean(name=\"i_loss\")\n",
    "        self.kid = KID(name=\"kid\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.noise_loss_tracker, self.image_loss_tracker, self.kid]\n",
    "\n",
    "    def denormalize(self, images):\n",
    "        # convert the pixel values back to 0-1 range\n",
    "        images = self.normalizer.mean + images * self.normalizer.variance**0.5\n",
    "        return tf.clip_by_value(images, 0.0, 1.0)\n",
    "\n",
    "    def diffusion_schedule(self, diffusion_times):\n",
    "        # diffusion times -> angles\n",
    "        start_angle = tf.acos(max_signal_rate)\n",
    "        end_angle = tf.acos(min_signal_rate)\n",
    "\n",
    "        diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
    "\n",
    "        # angles -> signal and noise rates\n",
    "        signal_rates = tf.cos(diffusion_angles)\n",
    "        noise_rates = tf.sin(diffusion_angles)\n",
    "        # note that their squared sum is always: sin^2(x) + cos^2(x) = 1\n",
    "\n",
    "        return noise_rates, signal_rates\n",
    "\n",
    "    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n",
    "        # the exponential moving average weights are used at evaluation\n",
    "        if training:\n",
    "            network = self.network\n",
    "        else:\n",
    "            network = self.ema_network\n",
    "\n",
    "        # predict noise component and calculate the image component using it\n",
    "        pred_noises = network([noisy_images, noise_rates**2], training=training)\n",
    "        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
    "\n",
    "        return pred_noises, pred_images\n",
    "\n",
    "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
    "        # reverse diffusion = sampling\n",
    "        num_images = initial_noise.shape[0]\n",
    "        step_size = 1.0 / diffusion_steps\n",
    "\n",
    "        # important line:\n",
    "        # at the first sampling step, the \"noisy image\" is pure noise\n",
    "        # but its signal rate is assumed to be nonzero (min_signal_rate)\n",
    "        next_noisy_images = initial_noise\n",
    "        for step in range(diffusion_steps):\n",
    "            noisy_images = next_noisy_images\n",
    "\n",
    "            # separate the current noisy image to its components\n",
    "            diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size\n",
    "            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
    "            pred_noises, pred_images = self.denoise(\n",
    "                noisy_images, noise_rates, signal_rates, training=False\n",
    "            )\n",
    "            # network used in eval mode\n",
    "\n",
    "            # remix the predicted components using the next signal and noise rates\n",
    "            next_diffusion_times = diffusion_times - step_size\n",
    "            next_noise_rates, next_signal_rates = self.diffusion_schedule(\n",
    "                next_diffusion_times\n",
    "            )\n",
    "            next_noisy_images = (\n",
    "                next_signal_rates * pred_images + next_noise_rates * pred_noises\n",
    "            )\n",
    "            # this new noisy image will be used in the next step\n",
    "\n",
    "        return pred_images\n",
    "\n",
    "    def generate(self, num_images, diffusion_steps):\n",
    "        # noise -> images -> denormalized images\n",
    "        initial_noise = tf.random.normal(shape=(num_images, image_size, image_size, 3))\n",
    "        generated_images = self.reverse_diffusion(initial_noise, diffusion_steps)\n",
    "        generated_images = self.denormalize(generated_images)\n",
    "        return generated_images\n",
    "\n",
    "    def train_step(self, images):\n",
    "        # normalize images to have standard deviation of 1, like the noises\n",
    "        images = self.normalizer(images, training=True)\n",
    "        noises = tf.random.normal(shape=(batch_size, image_size, image_size, 3))\n",
    "\n",
    "        # sample uniform random diffusion times\n",
    "        diffusion_times = tf.random.uniform(\n",
    "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
    "        # mix the images with noises accordingly\n",
    "        noisy_images = signal_rates * images + noise_rates * noises\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # train the network to separate noisy images to their components\n",
    "            pred_noises, pred_images = self.denoise(\n",
    "                noisy_images, noise_rates, signal_rates, training=True\n",
    "            )\n",
    "\n",
    "            noise_loss = self.loss(noises, pred_noises)  # used for training\n",
    "            image_loss = self.loss(images, pred_images)  # only used as metric\n",
    "\n",
    "        gradients = tape.gradient(noise_loss, self.network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n",
    "\n",
    "        self.noise_loss_tracker.update_state(noise_loss)\n",
    "        self.image_loss_tracker.update_state(image_loss)\n",
    "\n",
    "        # track the exponential moving averages of weights\n",
    "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
    "            ema_weight.assign(ema * ema_weight + (1 - ema) * weight)\n",
    "\n",
    "        # KID is not measured during the training phase for computational efficiency\n",
    "        return {m.name: m.result() for m in self.metrics[:-1]}\n",
    "\n",
    "    def test_step(self, images):\n",
    "        # normalize images to have standard deviation of 1, like the noises\n",
    "        images = self.normalizer(images, training=False)\n",
    "        noises = tf.random.normal(shape=(batch_size, image_size, image_size, 3))\n",
    "\n",
    "        # sample uniform random diffusion times\n",
    "        diffusion_times = tf.random.uniform(\n",
    "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
    "        # mix the images with noises accordingly\n",
    "        noisy_images = signal_rates * images + noise_rates * noises\n",
    "\n",
    "        # use the network to separate noisy images to their components\n",
    "        pred_noises, pred_images = self.denoise(\n",
    "            noisy_images, noise_rates, signal_rates, training=False\n",
    "        )\n",
    "\n",
    "        noise_loss = self.loss(noises, pred_noises)\n",
    "        image_loss = self.loss(images, pred_images)\n",
    "\n",
    "        self.image_loss_tracker.update_state(image_loss)\n",
    "        self.noise_loss_tracker.update_state(noise_loss)\n",
    "\n",
    "        # measure KID between real and generated images\n",
    "        # this is computationally demanding, kid_diffusion_steps has to be small\n",
    "        images = self.denormalize(images)\n",
    "        generated_images = self.generate(\n",
    "            num_images=batch_size, diffusion_steps=kid_diffusion_steps\n",
    "        )\n",
    "        self.kid.update_state(images, generated_images)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def plot_images(self, epoch=None, logs=None, num_rows=3, num_cols=6):\n",
    "        # plot random generated images for visual evaluation of generation quality\n",
    "        generated_images = self.generate(\n",
    "            num_images=num_rows * num_cols,\n",
    "            diffusion_steps=plot_diffusion_steps,\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(num_cols * 2.0, num_rows * 2.0))\n",
    "        for row in range(num_rows):\n",
    "            for col in range(num_cols):\n",
    "                index = row * num_cols + col\n",
    "                plt.subplot(num_rows, num_cols, index + 1)\n",
    "                plt.imshow(generated_images[index])\n",
    "                plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and compile the model\n",
    "model = DiffusionModel(image_size, widths, block_depth)\n",
    "# below tensorflow 2.9:\n",
    "# pip install tensorflow_addons\n",
    "import tensorflow_addons as tfa\n",
    "# optimizer=tfa.optimizers.AdamW\n",
    "model.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    ),\n",
    "    loss=keras.losses.mean_absolute_error,\n",
    ")\n",
    "# pixelwise mean absolute error is used as loss\n",
    "\n",
    "# save the best model based on the validation KID metric\n",
    "checkpoint_path = \"checkpoints/diffusion_model\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_kid\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "# calculate mean and variance of training dataset for normalization\n",
    "model.normalizer.adapt(tf_train_x)\n",
    "\n",
    "# run training and plot generated images periodically\n",
    "for i in range(100):\n",
    "    model.plot_images()\n",
    "    model.fit(\n",
    "    tf_train_x,\n",
    "    epochs=num_epochs)\n",
    "    model.save_weights(\"../model/Diffusion/embro/model\"+str(i)+\".tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    model.plot_images()\n",
    "    model.fit(\n",
    "    tf_train_x,\n",
    "    epochs=num_epochs)\n",
    "    model.save_weights(\"../model/Diffusion/embro/model\"+str(i)+\".tf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ace6096bc4ec7c9763b7a7f8aba72601b4924b997cc8a285eb70b9b69117778c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
